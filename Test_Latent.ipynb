{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524efc5-0d7f-4829-a4a9-e5b4f47b6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from datasets import Priv_NAMES as DATASET_NAMES\n",
    "from datasets import get_private_dataset\n",
    "from models import get_all_models, get_model\n",
    "from utils.Server import train\n",
    "from utils.Toolbox_analysis import create_latent_df, process_latent_df\n",
    "from utils.Toolbox_visualization import format_latent_dict, load_and_scale_data, combine_latents, plot_latent_heatmap, plot_time_series_and_latents\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def parse_args():\n",
    "    parser = ArgumentParser(description='You Only Need Me', allow_abbrev=False)\n",
    "    parser.add_argument('--device_id', type=int, default=0, help='The Device Id for Experiment')\n",
    "    parser.add_argument('--run_simulation', type=bool, default=True, help='The Device Id for Experiment')\n",
    "    parser.add_argument('--detect_anomalies', type=bool, default=False)\n",
    "    parser.add_argument('--generate_viz', type=bool, default=True, help='Creates and saves interactive visualizations')\n",
    "\n",
    "\n",
    "    # Communication - epochs\n",
    "    parser.add_argument('--communication_epoch', type=int, default=3,\n",
    "                        help='The Communication Epoch in Federated Learning')\n",
    "    parser.add_argument('--local_epoch', type=int, default=3, help='The Local Epoch for each Participant')\n",
    "\n",
    "    # Participants info\n",
    "    parser.add_argument('--parti_num', type=int, default=None, help='The Number for Participants. If \"None\" will be setted as the sum of values described in --domain')\n",
    "    parser.add_argument('--online_ratio', type=float, default=1, help='The Ratio for Online Clients')\n",
    "\n",
    "    # Data parameter\n",
    "    parser.add_argument('--dataset', type=str, default='fl_leaks', choices=DATASET_NAMES, help='Which scenario to perform experiments on.')\n",
    "    parser.add_argument('--experiment_id', type=str, default='Pipeline_Full', help='Experiment identifier')\n",
    "    parser.add_argument('--extra_coments', type=str, default='proto_month', help='Aditional info')\n",
    "    parser.add_argument('--domains', type=dict, default={\n",
    "                                                        'Graeme': 5,\n",
    "                                                        # 'Balerma': 3,\n",
    "                                                        },\n",
    "                        help='Domains and respective number of participants.')\n",
    "\n",
    "    ## Time series preprocessing\n",
    "    parser.add_argument('--interval_agg', type=int, default=2 * 60 ** 2,\n",
    "                        help='Agregation interval (seconds) of time series')\n",
    "    parser.add_argument('--window_size', type=int, default=84, help='Rolling window length')\n",
    "\n",
    "    # Model (AER) parameters\n",
    "    parser.add_argument('--input_size', type=int, default=5, help='Number of sensors')  #TODO adaptar\n",
    "    parser.add_argument('--output_size', type=int, default=5, help='Shape output - dense layer')\n",
    "    parser.add_argument('--lstm_units', type=int, default=30,\n",
    "                        help='Number of LSTM units (the latent space will have dimension 2 times bigger')\n",
    "    \n",
    "\n",
    "    # Federated parameters\n",
    "    parser.add_argument('--model', type=str, default='fpl', help='Federated Model name.', choices=get_all_models()) #fedavg\n",
    "\n",
    "    parser.add_argument('--structure', type=str, default='homogeneity')\n",
    "\n",
    "    parser.add_argument('--pri_aug', type=str, default='weak',  # weak strong\n",
    "                        help='Augmentation for Private Data')\n",
    "    parser.add_argument('--learning_decay', type=bool, default=False, help='The Option for Learning Rate Decay')\n",
    "    parser.add_argument('--averaging', type=str, default='weight', help='The Option for averaging strategy')\n",
    "\n",
    "    parser.add_argument('--infoNCET', type=float, default=0.02, help='The InfoNCE temperature')\n",
    "    parser.add_argument('--T', type=float, default=0.05, help='The Knowledge distillation temperature')\n",
    "    parser.add_argument('--weight', type=int, default=1, help='The Weigth for the distillation loss')\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    if args.parti_num is None:\n",
    "        args.parti_num = sum(args.domains.values())\n",
    "\n",
    "    return args\n",
    "\n",
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c814ad1-4a1e-4ad0-84d0-d47b789f5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_int = 2\n",
    "results_id = f'{args.experiment_id}_{args.communication_epoch}_{args.local_epoch}_{agg_int}_{args.window_size}_{args.extra_coments}'\n",
    "\n",
    "results_path = f\"results/results_{results_id}.pkl\"\n",
    "latent_path = f\"results/{results_id}.pkl\"\n",
    "\n",
    "\n",
    "with open(latent_path, 'rb') as f:\n",
    "    latent_dfs = pickle.load(f)\n",
    "\n",
    "format_latent_dict(latent_dfs)\n",
    "scaled_df = load_and_scale_data(id_network = 'Graeme', id_experiment = args.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f98b6f-e2e4-44fa-9299-0fe982041aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = combine_latents(latent_dfs)\n",
    "plot_latent_heatmap(df_combined, results_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8047d-aa82-404d-aa6d-21c51e87081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series_and_latents(df_combined, scaled_df, results_id, batch_temporal=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200fb8c-2001-4456-876c-dbb92b2d38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "batch_temporal=2\n",
    "epoch_tgt = args.communication_epoch - 1\n",
    "# --- Prepare data ---\n",
    "\n",
    "melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "melted_df['month'] = melted_df['timestamp'].dt.month\n",
    "\n",
    "# Filter to a specific epoch\n",
    "df_combined['month'] = df_combined['timestamp'].dt.month\n",
    "# df['month'] = df['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "\n",
    "# Offset values per feature\n",
    "unique_features = melted_df['feature'].unique()\n",
    "offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}\n",
    "melted_df['offset_value'] = melted_df.apply(\n",
    "    lambda row: row['value'] + offset_dict[row['feature']], axis=1\n",
    ")\n",
    "\n",
    "# --- Selections ---\n",
    "start_ts = melted_df['timestamp'].min()\n",
    "end_ts = start_ts + pd.Timedelta(days=batch_temporal)\n",
    "date_range = (start_ts.to_pydatetime(), end_ts.to_pydatetime())\n",
    "\n",
    "brush = alt.selection_interval(encodings=['x'], value={'x': date_range})\n",
    "latent_selection = alt.selection_point(fields=['timestamp'], value=melted_df['timestamp'].min())\n",
    "\n",
    "hour_options = [None] + sorted(df['month'].unique().tolist())\n",
    "hour_selection = alt.selection_point(\n",
    "    name=\"Select Month\", \n",
    "    fields=['month'], \n",
    "    bind=alt.binding_select(options=hour_options, name='Month: '),\n",
    "    value=None\n",
    ")\n",
    "\n",
    "# --- Time Series Plot Setup ---\n",
    "base = alt.Chart(melted_df).mark_line().encode(\n",
    "    x=alt.X('timestamp:T', title='Time'),\n",
    "    y=alt.Y('offset_value:Q', title='Offset Scaled Value'),\n",
    "    color=alt.Color('feature:N', title='Feature')\n",
    ").properties(width=500)\n",
    "\n",
    "highlighted_points = alt.Chart(melted_df).mark_circle(color='black', size=5).encode(\n",
    "    x='timestamp:T',\n",
    "    y='offset_value:Q',\n",
    "    tooltip=['feature:N', 'timestamp:T']\n",
    ").transform_filter(\n",
    "    hour_selection\n",
    ")\n",
    "\n",
    "upper = (base + highlighted_points).encode(\n",
    "    x=alt.X('timestamp:T', scale=alt.Scale(domain=brush))\n",
    ").properties(\n",
    "    height=200\n",
    ")\n",
    "\n",
    "lower = base.properties(height=60).add_params(brush)\n",
    "\n",
    "time_series_chart = upper & lower\n",
    "\n",
    "# --- Latent Space Plot with Hour Filtering ---\n",
    "\n",
    "epoch_slider = alt.binding_range(min=df_combined['epoch'].min(),\n",
    "                                 max=df_combined['epoch'].max(),\n",
    "                                 step=1,\n",
    "                                 name='Epoch: ')\n",
    "epoch_select = alt.selection_point (fields=['epoch'], bind=epoch_slider, value = 0)\n",
    "\n",
    "\n",
    "x_range = [int(df_combined['latent_1'].min()) - 3, int(df_combined['latent_1'].max()) + 3]\n",
    "y_range = [int(df_combined['latent_2'].min()) - 3, int(df_combined['latent_2'].max()) + 3]\n",
    "\n",
    "latent = alt.Chart(df_combined).mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=75), scale=alt.Scale(domain=x_range), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=75), scale=alt.Scale(domain=y_range), title=\"Latent y\"),\n",
    "    color=alt.Color('label:N', scale=alt.Scale(scheme='tableau20'), title='Density'),\n",
    "    tooltip=['label:N', 'timestamp:T', 'month:O']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title=\"Latent Space (highlight by hour)\"\n",
    ").add_params(\n",
    "    latent_selection,\n",
    "    hour_selection,\n",
    "    epoch_select\n",
    ").transform_filter(\n",
    "    brush\n",
    ").transform_filter(\n",
    "    hour_selection\n",
    ").transform_filter(\n",
    "    epoch_select\n",
    ").interactive()\n",
    "\n",
    "# --- Final Layout ---\n",
    "final_plot = latent | time_series_chart\n",
    "\n",
    "# final_plot.save(f'results/imgs/Series_{results_id}_proto_month.html')\n",
    "final_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51bef2-6136-4fe5-b2c7-c4ffc92ae1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Combine all epoch dataframes into one DataFrame\n",
    "df_all = []\n",
    "\n",
    "for epoch, df_epoch in latent_dfs['Baseline'].items():\n",
    "    for method in ['pca_scl', 'umap_scl']:\n",
    "        df = df_epoch[method].copy()\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp format\n",
    "        df['epoch'] = epoch  # Add epoch column\n",
    "        df['method'] = method\n",
    "        df_all.append(df)\n",
    "\n",
    "df_combined = pd.concat(df_all, ignore_index=True)\n",
    "df_combined['month'] = df_combined['timestamp'].dt.month\n",
    "\n",
    "# Step 2: Create selection slider\n",
    "epoch_slider = alt.binding_range(min=df_combined['epoch'].min(),\n",
    "                                 max=df_combined['epoch'].max(),\n",
    "                                 step=1,\n",
    "                                 name='Epoch: ')\n",
    "epoch_select = alt.selection_point (fields=['epoch'], bind=epoch_slider, value = 0)\n",
    "\n",
    "hour_options = [None] + sorted(df_combined['month'].unique().tolist())\n",
    "hour_selection = alt.selection_point(\n",
    "    name=\"Select Hour\", \n",
    "    fields=['month'], \n",
    "    bind=alt.binding_select(options=hour_options, name='Hour: '),\n",
    "    value=None\n",
    ")\n",
    "\n",
    "method_options = df_combined['method'].unique().tolist()\n",
    "method_selection = alt.selection_point(\n",
    "    name=\"Select method\", \n",
    "    fields=['method'], \n",
    "    bind=alt.binding_select(options=method_options, name='Method: '),\n",
    "    value=method_options[0]\n",
    ")\n",
    "\n",
    "# Selection for color field\n",
    "color_field_selection = alt.selection_point(\n",
    "    name='ColorBy',\n",
    "    fields=['key'],\n",
    "    bind=alt.binding_select(options=['label', 'month'], name='Color by: '),\n",
    "    value='label'\n",
    ")\n",
    "\n",
    "# Fold label and month into key/value pairs\n",
    "folded = alt.Chart(df_combined).transform_filter(\n",
    "    epoch_select & hour_selection & method_selection\n",
    ").transform_fold(\n",
    "    ['label', 'month'],\n",
    "    as_=['key', 'value']\n",
    ").transform_filter(\n",
    "    color_field_selection\n",
    ").mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=100), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=100), title=\"Latent y\"),\n",
    "    color=alt.Color('value:N', scale=alt.Scale(scheme='tableau20'), title='Color'),\n",
    "    tooltip=['label:N', 'month:Q', 'epoch:Q']\n",
    ").add_params(\n",
    "    epoch_select,\n",
    "    hour_selection,\n",
    "    method_selection,\n",
    "    color_field_selection\n",
    ").properties(\n",
    "    width=350,\n",
    "    height=350,\n",
    "    title=\"Interactive Latent Space Heatmap (Color-coded)\"\n",
    ").interactive()\n",
    "\n",
    "controls = alt.Chart(df_combined).mark_point().encode().add_params(\n",
    "    epoch_select,\n",
    "    hour_selection,\n",
    "    method_selection,\n",
    "    color_field_selection\n",
    ").properties(\n",
    "    title=\"Controls\"\n",
    ")\n",
    "\n",
    "# folded.save(f'results/imgs/Heat_{results_id}_proto_month.html')\n",
    "\n",
    "folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500e381-146a-4383-9b05-1f94e94b2ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0dbc63-de51-4758-9b5e-5b257e232b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f354e8-393e-4682-875c-943ed7634278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb7edc-5697-48b6-be3b-f0930b207428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff26f3-2796-42ae-884b-76eccf7b79ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:59:09.644162Z",
     "start_time": "2025-05-22T08:59:07.177249Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "form.vega-bindings {\n",
    "  position: absolute;\n",
    "  right: 0px;\n",
    "  top: 0px;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65173a2a50c6b414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:59:10.408503Z",
     "start_time": "2025-05-22T08:59:10.336060Z"
    }
   },
   "outputs": [],
   "source": [
    "id_network = 'Graeme'\n",
    "id_experiment = 'PIPELINE_PATTERNS'\n",
    "\n",
    "comm_epoch = 8\n",
    "local_epoch = 3\n",
    "\n",
    "agg_interval = 2\n",
    "window_size = 84\n",
    "results_id = f'{id_network}_{id_experiment}_{agg_interval}_{window_size}'\n",
    "\n",
    "batch_temporal = (agg_interval * window_size) / 24\n",
    "\n",
    "file_path = f'results/exp_latente_df_graeme_{id_experiment}_{comm_epoch}_{local_epoch}_{agg_interval}_{window_size}_proto_month.pkl'\n",
    "\n",
    "# file_path = f'results/exp_latente_df_{id_network.lower()}_{agg_interval}_{window_size}_proto_month_30_old.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    latent_dfs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad9353eb3cfd4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:59:11.227751Z",
     "start_time": "2025-05-22T08:59:11.170149Z"
    }
   },
   "outputs": [],
   "source": [
    "for case in latent_dfs.values():\n",
    "    for epoch in case.values():\n",
    "        date_cols = epoch['latent_space'].iloc[:, :4].reset_index(drop=True)\n",
    "        for space in epoch.keys():\n",
    "            if ('pca' in space) or ('umap' in space):\n",
    "                epoch[space] = pd.concat([date_cols, epoch[space]], axis = 1)\n",
    "                epoch[space].columns = date_cols.columns.tolist() + ['latent_1', 'latent_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d788baf-0943-4508-a194-39bdb8e81523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:59:12.221392Z",
     "start_time": "2025-05-22T08:59:12.184480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "client_A = pd.read_csv(f'datasets/leaks/{id_network}/{id_experiment}/ClientA_Baseline.csv')\n",
    "\n",
    "# Extract timestamps\n",
    "timestamps = pd.to_datetime(client_A['timestamp'], unit='s')\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Scale features (excluding timestamp)\n",
    "scaled_values = scaler.fit_transform(client_A.iloc[:, 1:])\n",
    "\n",
    "# Convert scaled data back to DataFrame with original column names (except timestamp)\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=client_A.columns[1:])\n",
    "\n",
    "# Add timestamp as the first column\n",
    "scaled_df.insert(0, 'timestamp', timestamps)\n",
    "\n",
    "# Check shape\n",
    "scaled_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820db1c-b162-41db-92eb-49efea3a8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Combine all epoch dataframes into one DataFrame\n",
    "df_all = []\n",
    "\n",
    "for epoch, df_epoch in latent_dfs['Baseline'].items():\n",
    "    for method in ['pca_scl', 'umap_scl']:\n",
    "        df = df_epoch[method].copy()\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp format\n",
    "        df['epoch'] = epoch  # Add epoch column\n",
    "        df['method'] = method\n",
    "        df_all.append(df)\n",
    "\n",
    "df_combined = pd.concat(df_all, ignore_index=True)\n",
    "df_combined['hour_filter'] = df_combined['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "df_combined['month'] = df_combined['timestamp'].dt.month\n",
    "\n",
    "# Step 2: Create selection slider\n",
    "epoch_slider = alt.binding_range(min=df_combined['epoch'].min(),\n",
    "                                 max=df_combined['epoch'].max(),\n",
    "                                 step=1,\n",
    "                                 name='Epoch: ')\n",
    "epoch_select = alt.selection_point (fields=['epoch'], bind=epoch_slider, value = 0)\n",
    "\n",
    "hour_options = [None] + sorted(df_combined['hour_filter'].unique().tolist())\n",
    "hour_selection = alt.selection_point(\n",
    "    name=\"Select Hour\", \n",
    "    fields=['hour_filter'], \n",
    "    bind=alt.binding_select(options=hour_options, name='Hour: '),\n",
    "    value=None\n",
    ")\n",
    "\n",
    "method_options = df_combined['method'].unique().tolist()\n",
    "method_selection = alt.selection_point(\n",
    "    name=\"Select method\", \n",
    "    fields=['method'], \n",
    "    bind=alt.binding_select(options=method_options, name='Method: '),\n",
    "    value=method_options[0]\n",
    ")\n",
    "\n",
    "# Selection for color field\n",
    "color_field_selection = alt.selection_point(\n",
    "    name='ColorBy',\n",
    "    fields=['key'],\n",
    "    bind=alt.binding_select(options=['label', 'hour_filter', 'month'], name='Color by: '),\n",
    "    value='label'\n",
    ")\n",
    "\n",
    "# Fold label and hour_filter into key/value pairs\n",
    "folded = alt.Chart(df_combined).transform_filter(\n",
    "    epoch_select & hour_selection & method_selection\n",
    ").transform_fold(\n",
    "    ['label', 'hour_filter', 'month'],\n",
    "    as_=['key', 'value']\n",
    ").transform_filter(\n",
    "    color_field_selection\n",
    ").mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=100), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=100), title=\"Latent y\"),\n",
    "    color=alt.Color('value:N', scale=alt.Scale(scheme='tableau20'), title='Color'),\n",
    "    tooltip=['label:N', 'hour_filter:Q', 'epoch:Q']\n",
    ").add_params(\n",
    "    epoch_select,\n",
    "    hour_selection,\n",
    "    method_selection,\n",
    "    color_field_selection\n",
    ").properties(\n",
    "    width=350,\n",
    "    height=350,\n",
    "    title=\"Interactive Latent Space Heatmap (Color-coded)\"\n",
    ").interactive()\n",
    "\n",
    "controls = alt.Chart(df_combined).mark_point().encode().add_params(\n",
    "    epoch_select,\n",
    "    hour_selection,\n",
    "    method_selection,\n",
    "    color_field_selection\n",
    ").properties(\n",
    "    title=\"Controls\"\n",
    ")\n",
    "\n",
    "# folded.save(f'results/imgs/Heat_{results_id}_proto_hour.html')\n",
    "\n",
    "folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a364837-51e9-49af-a1fc-511d44aef344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_heatmap(df_combined, results_id):\n",
    "    \"\"\"Creates and saves an interactive heatmap of the latent space.\n",
    "    :param period:\n",
    "    \"\"\"\n",
    "    epoch_slider = alt.binding_range(min=df_combined['epoch'].min(), max=df_combined['epoch'].max(), step=1, name='Epoch: ')\n",
    "    epoch_select = alt.selection_point(fields=['epoch'], bind=epoch_slider, value=0)\n",
    "\n",
    "    hour_options = [None] + sorted(df_combined['hour_filter'].unique().tolist())\n",
    "    hour_selection = alt.selection_point(fields=['hour_filter'], bind=alt.binding_select(options=hour_options, name=f'Hour: '), value=None)\n",
    "\n",
    "    month_options = [None] + sorted(df_combined['month'].unique().tolist())\n",
    "    month_selection = alt.selection_point(fields=['month'], bind=alt.binding_select(options=month_options, name=f'Month: '), value=None)\n",
    "\n",
    "    method_options = df_combined['method'].unique().tolist()\n",
    "    method_selection = alt.selection_point(fields=['method'], bind=alt.binding_select(options=method_options, name='Method: '), value=method_options[0])\n",
    "\n",
    "    color_field_selection = alt.selection_point(fields=['key'], bind=alt.binding_select(options=['label', 'hour_filter', 'month'], name='Color by: '), value='label')\n",
    "\n",
    "    folded = alt.Chart(df_combined).transform_filter(\n",
    "        epoch_select & month_selection & hour_selection & method_selection\n",
    "    ).transform_fold(\n",
    "        ['label', 'hour_filter', 'month'], as_=['key', 'value']\n",
    "    ).transform_filter(\n",
    "        color_field_selection\n",
    "    ).mark_rect().encode(\n",
    "        x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=100), title=\"Latent x\"),\n",
    "        y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=100), title=\"Latent y\"),\n",
    "        color=alt.Color('value:N', scale=alt.Scale(scheme='tableau20'), title='Color'),\n",
    "        tooltip=['label:N', 'month:Q', 'hour:Q', 'epoch:Q']\n",
    "    ).add_params(\n",
    "        epoch_select, month_selection, hour_selection, method_selection, color_field_selection\n",
    "    ).properties(\n",
    "        width=350,\n",
    "        height=350,\n",
    "        title=\"Interactive Latent Space Heatmap (Color-coded)\"\n",
    "    ).interactive()\n",
    "\n",
    "    # folded.save(f'results/imgs/Heat_{results_id}_proto.html')\n",
    "    return folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b3203b157cdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = combine_latents(latent_dfs)\n",
    "df_combined['hour_filter'] = df_combined['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "df_combined['month'] = df_combined['timestamp'].dt.month\n",
    "\n",
    "plot = plot_latent_heatmap(df_combined, results_id)\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f0426e-6a60-4b78-9e10-60feab6b47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series_and_latents(df_combined, scaled_df, results_id, batch_temporal=14):\n",
    "    \"\"\"Creates and saves the combined plot of time-series and filtered latent space.\n",
    "    :param period:\n",
    "    \"\"\"\n",
    "    melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "    melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "    melted_df['month'] = melted_df['timestamp'].dt.month\n",
    "\n",
    "    melted_df['hour'] = melted_df['timestamp'].dt.hour\n",
    "    melted_df['hour_filter'] = melted_df['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "\n",
    "    # Offset time-series values for stacking\n",
    "    unique_features = melted_df['feature'].unique()\n",
    "    offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}\n",
    "    melted_df['offset_value'] = melted_df.apply(lambda row: row['value'] + offset_dict[row['feature']], axis=1)\n",
    "\n",
    "    # --- Selections ---\n",
    "    start_ts = melted_df['timestamp'].min()\n",
    "    end_ts = start_ts + pd.Timedelta(days=batch_temporal)\n",
    "    brush = alt.selection_interval(encodings=['x'], value={'x': (start_ts, end_ts)})\n",
    "    latent_selection = alt.selection_point(fields=['timestamp'], value=melted_df['timestamp'].min())\n",
    "\n",
    "    hour_options = [None] + sorted(df_combined['hour_filter'].unique().tolist())\n",
    "    hour_selection = alt.selection_point(\n",
    "        name=f\"Select Hour:\",\n",
    "        fields=['hour_filter'],\n",
    "        bind=alt.binding_select(options=hour_options, name=f'Hour: '),\n",
    "        value=None)\n",
    "\n",
    "    month_options = [None] + sorted(df_combined['month'].unique().tolist())\n",
    "    month_selection = alt.selection_point(\n",
    "        name=f\"Select Month:\",\n",
    "        fields=['month'],\n",
    "        bind=alt.binding_select(options=month_options, name=f'Month: '),\n",
    "        value=None)\n",
    "\n",
    "    method_options = df_combined['method'].unique().tolist()\n",
    "    method_selection = alt.selection_point(fields=['method'], bind=alt.binding_select(options=method_options, name='Method: '), value=method_options[0])\n",
    "\n",
    "    # --- Time Series Chart ---\n",
    "    base = alt.Chart(melted_df).mark_line().encode(\n",
    "        x='timestamp:T',\n",
    "        y='offset_value:Q',\n",
    "        color='feature:N'\n",
    "    ).properties(width=500)\n",
    "\n",
    "    points = alt.Chart(melted_df).mark_circle(color='black', size=5).encode(\n",
    "        x='timestamp:T',\n",
    "        y='offset_value:Q',\n",
    "        tooltip=['feature:N', 'timestamp:T']\n",
    "    ).transform_filter(month_selection & hour_selection)\n",
    "\n",
    "    upper = (base + points).encode(\n",
    "        x=alt.X('timestamp:T', scale=alt.Scale(domain=brush))\n",
    "    ).properties(height=200)\n",
    "\n",
    "    lower = base.properties(height=60).add_params(brush)\n",
    "\n",
    "    time_series_chart = upper & lower\n",
    "\n",
    "    # --- Latent Space Chart ---\n",
    "    x_range = [int(df_combined['latent_1'].min()) - 3, int(df_combined['latent_1'].max()) + 3]\n",
    "    y_range = [int(df_combined['latent_2'].min()) - 3, int(df_combined['latent_2'].max()) + 3]\n",
    "    \n",
    "    epoch_slider = alt.binding_range(min=df_combined['epoch'].min(),\n",
    "                                 max=df_combined['epoch'].max(),\n",
    "                                 step=1,\n",
    "                                 name='Epoch: ')\n",
    "    epoch_select = alt.selection_point (fields=['epoch'], bind=epoch_slider, value = 0)\n",
    "\n",
    "    color_field_selection = alt.selection_point(fields=['key'], bind=alt.binding_select(options=['label', 'hour_filter', 'month'], name='Color by: '), value='label')\n",
    "\n",
    "    latent = alt.Chart(df_combined).transform_filter(\n",
    "        brush & epoch_select & month_selection & hour_selection & method_selection\n",
    "    ).transform_fold(\n",
    "        ['label', 'hour_filter', 'month'], as_=['key', 'value']\n",
    "    ).transform_filter(\n",
    "        color_field_selection\n",
    "    ).mark_rect().encode(\n",
    "        x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=100), title=\"Latent x\"),\n",
    "        y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=100), title=\"Latent y\"),\n",
    "        color=alt.Color('value:N', scale=alt.Scale(scheme='tableau20'), title='Color'),\n",
    "        tooltip=['label:N', 'month:Q', 'hour:Q', 'epoch:Q']\n",
    "    ).add_params(\n",
    "        latent_selection, epoch_select, month_selection, hour_selection, method_selection, color_field_selection\n",
    "    ).properties(\n",
    "        width=350,\n",
    "        height=350,\n",
    "        title=\"Interactive Latent Space Heatmap (Color-coded)\"\n",
    "    ).interactive()\n",
    "\n",
    "\n",
    "    # --- Layout and Save ---\n",
    "    final_plot = latent | time_series_chart\n",
    "    return final_plot\n",
    "\n",
    "\n",
    "plot = plot_time_series_and_latents(df_combined, scaled_df, results_id)\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36d69f-d767-41b2-ae17-723220df6070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e88961-4574-412b-a4ec-4f8d3d9e1f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c80d0-7e0c-4c14-8c8a-cac26c0d9e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea76be3-f212-4853-8da4-ff57eeeaa2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Combine all epoch dataframes into one DataFrame\n",
    "df_all = []\n",
    "\n",
    "for epoch, df_epoch in latent_dfs['Baseline'].items():\n",
    "    for method in ['pca_scl', 'umap_scl']:\n",
    "        df = df_epoch[method].copy()\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp format\n",
    "        df['epoch'] = epoch  # Add epoch column\n",
    "        df['method'] = method\n",
    "        df_all.append(df)\n",
    "\n",
    "df_combined = pd.concat(df_all, ignore_index=True)\n",
    "df_combined['month'] = df_combined['timestamp'].dt.month\n",
    "\n",
    "# Step 2: Create selection slider\n",
    "epoch_slider = alt.binding_range(min=df_combined['epoch'].min(),\n",
    "                                 max=df_combined['epoch'].max(),\n",
    "                                 step=1,\n",
    "                                 name='Epoch: ')\n",
    "epoch_select = alt.selection_point (fields=['epoch'], bind=epoch_slider, value = 0)\n",
    "\n",
    "hour_options = [None] + sorted(df_combined['month'].unique().tolist())\n",
    "hour_selection = alt.selection_point(\n",
    "    name=\"Select Hour\", \n",
    "    fields=['month'], \n",
    "    bind=alt.binding_select(options=hour_options, name='Hour: '),\n",
    "    value=None\n",
    ")\n",
    "\n",
    "method_options = df_combined['method'].unique().tolist()\n",
    "method_selection = alt.selection_point(\n",
    "    name=\"Select method\", \n",
    "    fields=['method'], \n",
    "    bind=alt.binding_select(options=method_options, name='Method: '),\n",
    "    value=method_options[0]\n",
    ")\n",
    "\n",
    "# Selection for color field\n",
    "color_field_selection = alt.selection_point(\n",
    "    name='ColorBy',\n",
    "    fields=['key'],\n",
    "    bind=alt.binding_select(options=['label', 'month'], name='Color by: '),\n",
    "    value='label'\n",
    ")\n",
    "\n",
    "# Fold label and month into key/value pairs\n",
    "folded = alt.Chart(df_combined).transform_filter(\n",
    "    epoch_select & hour_selection & method_selection\n",
    ").transform_fold(\n",
    "    ['label', 'month'],\n",
    "    as_=['key', 'value']\n",
    ").transform_filter(\n",
    "    color_field_selection\n",
    ").mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=100), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=100), title=\"Latent y\"),\n",
    "    color=alt.Color('value:N', scale=alt.Scale(scheme='tableau20'), title='Color'),\n",
    "    tooltip=['label:N', 'month:Q', 'epoch:Q']\n",
    ").add_params(\n",
    "    epoch_select,\n",
    "    hour_selection,\n",
    "    method_selection,\n",
    "    color_field_selection\n",
    ").properties(\n",
    "    width=350,\n",
    "    height=350,\n",
    "    title=\"Interactive Latent Space Heatmap (Color-coded)\"\n",
    ").interactive()\n",
    "\n",
    "controls = alt.Chart(df_combined).mark_point().encode().add_params(\n",
    "    epoch_select,\n",
    "    hour_selection,\n",
    "    method_selection,\n",
    "    color_field_selection\n",
    ").properties(\n",
    "    title=\"Controls\"\n",
    ")\n",
    "\n",
    "folded.save(f'results/imgs/Heat_{results_id}_proto_month.html')\n",
    "\n",
    "# folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0d2c5-49cb-4073-8b83-f809659fe267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120900dc-22b7-4ed3-9bea-681fc63ac658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8721d9-f15a-4ec0-84ce-2e7fd304edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare data ---\n",
    "melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "melted_df['hour'] = melted_df['timestamp'].dt.hour\n",
    "melted_df['hour_filter'] = melted_df['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "\n",
    "# Filter to a specific epoch\n",
    "df = df_combined[df_combined['epoch'] == 8].copy()\n",
    "df['hour_filter'] = df['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "\n",
    "# Offset values per feature\n",
    "unique_features = melted_df['feature'].unique()\n",
    "offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}\n",
    "melted_df['offset_value'] = melted_df.apply(\n",
    "    lambda row: row['value'] + offset_dict[row['feature']], axis=1\n",
    ")\n",
    "\n",
    "# --- Selections ---\n",
    "start_ts = melted_df['timestamp'].min()\n",
    "end_ts = start_ts + pd.Timedelta(days=batch_temporal)\n",
    "date_range = (start_ts.to_pydatetime(), end_ts.to_pydatetime())\n",
    "\n",
    "brush = alt.selection_interval(encodings=['x'], value={'x': date_range})\n",
    "latent_selection = alt.selection_point(fields=['timestamp'], value=melted_df['timestamp'].min())\n",
    "\n",
    "hour_options = [None] + sorted(df['hour_filter'].unique().tolist())\n",
    "hour_selection = alt.selection_point(\n",
    "    name=\"Select Hour\", \n",
    "    fields=['hour_filter'], \n",
    "    bind=alt.binding_select(options=hour_options, name='Hour: '),\n",
    "    value=None\n",
    ")\n",
    "\n",
    "# --- Time Series Plot Setup ---\n",
    "base = alt.Chart(melted_df).mark_line().encode(\n",
    "    x=alt.X('timestamp:T', title='Time'),\n",
    "    y=alt.Y('offset_value:Q', title='Offset Scaled Value'),\n",
    "    color=alt.Color('feature:N', title='Feature')\n",
    ").properties(width=500)\n",
    "\n",
    "highlighted_points = alt.Chart(melted_df).mark_circle(color='black', size=5).encode(\n",
    "    x='timestamp:T',\n",
    "    y='offset_value:Q',\n",
    "    tooltip=['feature:N', 'timestamp:T']\n",
    ").transform_filter(\n",
    "    hour_selection\n",
    ")\n",
    "\n",
    "upper = (base + highlighted_points).encode(\n",
    "    x=alt.X('timestamp:T', scale=alt.Scale(domain=brush))\n",
    ").properties(\n",
    "    height=200\n",
    ")\n",
    "\n",
    "lower = base.properties(height=60).add_params(brush)\n",
    "\n",
    "time_series_chart = upper & lower\n",
    "\n",
    "# --- Latent Space Plot with Hour Filtering ---\n",
    "x_range = [int(df['latent_1'].min()) - 3, int(df['latent_1'].max()) + 3]\n",
    "y_range = [int(df['latent_2'].min()) - 3, int(df['latent_2'].max()) + 3]\n",
    "\n",
    "latent = alt.Chart(df).mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=50), scale=alt.Scale(domain=x_range), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=50), scale=alt.Scale(domain=y_range), title=\"Latent y\"),\n",
    "    color=alt.Color('label:N', scale=alt.Scale(scheme='tableau20'), title='Density'),\n",
    "    tooltip=['label:N', 'timestamp:T', 'hour:O']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title=\"Latent Space (highlight by hour)\"\n",
    ").add_params(\n",
    "    latent_selection,\n",
    "    hour_selection\n",
    ").transform_filter(\n",
    "    brush\n",
    ").transform_filter(\n",
    "    hour_selection\n",
    ").interactive()\n",
    "\n",
    "# --- Final Layout ---\n",
    "final_plot = latent | time_series_chart\n",
    "\n",
    "final_plot.save(f'results/imgs/Series_{results_id}.html')\n",
    "final_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c3179-5c02-4993-9fe4-957f47b2f9f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:15:03.691921Z",
     "start_time": "2025-05-21T12:14:51.595216Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Prepare data ---\n",
    "melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "melted_df['month'] = melted_df['timestamp'].dt.month\n",
    "\n",
    "# Filter to a specific epoch\n",
    "df_combined['month'] = df_combined['timestamp'].dt.month\n",
    "df = df_combined[df_combined['epoch'] == 7].copy()\n",
    "# df['month'] = df['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "\n",
    "# Offset values per feature\n",
    "unique_features = melted_df['feature'].unique()\n",
    "offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}\n",
    "melted_df['offset_value'] = melted_df.apply(\n",
    "    lambda row: row['value'] + offset_dict[row['feature']], axis=1\n",
    ")\n",
    "\n",
    "# --- Selections ---\n",
    "start_ts = melted_df['timestamp'].min()\n",
    "end_ts = start_ts + pd.Timedelta(days=batch_temporal)\n",
    "date_range = (start_ts.to_pydatetime(), end_ts.to_pydatetime())\n",
    "\n",
    "brush = alt.selection_interval(encodings=['x'], value={'x': date_range})\n",
    "latent_selection = alt.selection_point(fields=['timestamp'], value=melted_df['timestamp'].min())\n",
    "\n",
    "hour_options = [None] + sorted(df['month'].unique().tolist())\n",
    "hour_selection = alt.selection_point(\n",
    "    name=\"Select Month\", \n",
    "    fields=['month'], \n",
    "    bind=alt.binding_select(options=hour_options, name='Month: '),\n",
    "    value=None\n",
    ")\n",
    "\n",
    "# --- Time Series Plot Setup ---\n",
    "base = alt.Chart(melted_df).mark_line().encode(\n",
    "    x=alt.X('timestamp:T', title='Time'),\n",
    "    y=alt.Y('offset_value:Q', title='Offset Scaled Value'),\n",
    "    color=alt.Color('feature:N', title='Feature')\n",
    ").properties(width=500)\n",
    "\n",
    "highlighted_points = alt.Chart(melted_df).mark_circle(color='black', size=5).encode(\n",
    "    x='timestamp:T',\n",
    "    y='offset_value:Q',\n",
    "    tooltip=['feature:N', 'timestamp:T']\n",
    ").transform_filter(\n",
    "    hour_selection\n",
    ")\n",
    "\n",
    "upper = (base + highlighted_points).encode(\n",
    "    x=alt.X('timestamp:T', scale=alt.Scale(domain=brush))\n",
    ").properties(\n",
    "    height=200\n",
    ")\n",
    "\n",
    "lower = base.properties(height=60).add_params(brush)\n",
    "\n",
    "time_series_chart = upper & lower\n",
    "\n",
    "# --- Latent Space Plot with Hour Filtering ---\n",
    "x_range = [int(df['latent_1'].min()) - 3, int(df['latent_1'].max()) + 3]\n",
    "y_range = [int(df['latent_2'].min()) - 3, int(df['latent_2'].max()) + 3]\n",
    "\n",
    "latent = alt.Chart(df).mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=50), scale=alt.Scale(domain=x_range), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=50), scale=alt.Scale(domain=y_range), title=\"Latent y\"),\n",
    "    color=alt.Color('label:N', scale=alt.Scale(scheme='tableau20'), title='Density'),\n",
    "    tooltip=['label:N', 'timestamp:T', 'month:O']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title=\"Latent Space (highlight by hour)\"\n",
    ").add_params(\n",
    "    latent_selection,\n",
    "    hour_selection\n",
    ").transform_filter(\n",
    "    brush\n",
    ").transform_filter(\n",
    "    hour_selection\n",
    ").interactive()\n",
    "\n",
    "# --- Final Layout ---\n",
    "final_plot = latent | time_series_chart\n",
    "\n",
    "final_plot.save(f'results/imgs/Series_{results_id}_proto_month.html')\n",
    "# final_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c839057-cddf-40d0-9bf9-f3b01481c0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4daec-49b1-4724-af7d-99b69efc9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "melted_df['hour'] = melted_df['timestamp'].dt.hour\n",
    "melted_df['day'] = melted_df['timestamp'].dt.day\n",
    "\n",
    "melted_df['hour_bin'] = (melted_df['hour'] // agg_interval) * agg_interval\n",
    "\n",
    "# Assign an offset per feature\n",
    "unique_features = melted_df['feature'].unique()\n",
    "offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}  # 2 is the vertical spacing\n",
    "\n",
    "# Apply the offset\n",
    "melted_df['offset_value'] = melted_df.apply(\n",
    "    lambda row: row['value'] + offset_dict[row['feature']], axis=1\n",
    ")\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "\n",
    "\n",
    "# Set up plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for feat in melted_df['feature'].unique():\n",
    "        \n",
    "    plot_df = melted_df[melted_df['feature'] == feat].copy()\n",
    "    plot_df = plot_df.iloc[:450, :]\n",
    "    # Make sure timestamp is a datetime object\n",
    "    plot_df['timestamp'] = pd.to_datetime(plot_df['timestamp'])\n",
    "    \n",
    "    # Set timestamp as index (optional but convenient for plotting)\n",
    "    plot_df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Plot full series in gray\n",
    "    plt.plot(plot_df.index, plot_df['offset_value'], color='lightgray', label='Full Series')\n",
    "    \n",
    "    # Define bins to plot and colors\n",
    "    bins_to_plot = [i for i in range (0, 12, agg_interval)]\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'purple', 'pink']\n",
    "    \n",
    "    # Loop over each bin\n",
    "    for bin_value, color in zip(bins_to_plot, colors):\n",
    "        for day in plot_df['day'].unique():\n",
    "            # Define the 4-hour window starting at bin_value\n",
    "            hour_range = [(bin_value + i) % 24 for i in range(4)]\n",
    "            \n",
    "            # Select the rows within that 4-hour window for the current day\n",
    "            mask = (plot_df['day'] == day) & (plot_df['hour'].isin(hour_range))\n",
    "            segment = plot_df[mask]\n",
    "    \n",
    "            # Plot the segment\n",
    "            plt.plot(segment.index, segment['offset_value'], color=color, label=f'Bin {bin_value}' if day == plot_df['day'].unique()[0] else \"\")\n",
    "    \n",
    "            # Define the 4-hour window starting at bin_value\n",
    "            hour_range = [(bin_value +12 + i) for i in range(4)]\n",
    "            \n",
    "            # Select the rows within that 4-hour window for the current day\n",
    "            mask = (plot_df['day'] == day) & (plot_df['hour'].isin(hour_range))\n",
    "            segment = plot_df[mask]\n",
    "    \n",
    "            # Plot the segment\n",
    "            plt.plot(segment.index, segment['offset_value'], color=color, label=f'Bin {bin_value}' if day == plot_df['day'].unique()[0] else \"\")\n",
    "        \n",
    "# Formatting\n",
    "plt.title(f'Series Highlighted for Hour Bins: {bins_to_plot} (4-hour blocks)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Offset Value')\n",
    "# plt.legend(loc='upper left', fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d1a5c-790f-47f8-a36c-79498eaa619e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea71503-7d7c-45c4-86e1-8796657781e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6811f-adc1-43b4-9723-a2c77f701849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Prepare data ---\n",
    "melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "\n",
    "df = df_combined[df_combined['epoch'] == 14]\n",
    "\n",
    "# Offset by feature\n",
    "unique_features = melted_df['feature'].unique()\n",
    "offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}\n",
    "melted_df['offset_value'] = melted_df.apply(\n",
    "    lambda row: row['value'] + offset_dict[row['feature']], axis=1\n",
    ")\n",
    "\n",
    "# --- Selection setup ---\n",
    "start_ts = melted_df['timestamp'].min()\n",
    "end_ts = start_ts + pd.Timedelta(days=batch_temporal)\n",
    "date_range = (start_ts.to_pydatetime(), end_ts.to_pydatetime())\n",
    "\n",
    "brush = alt.selection_interval(encodings=['x'], value={'x': date_range})\n",
    "latent_selection = alt.selection_point(fields=['timestamp'], value = melted_df['timestamp'].min())\n",
    "\n",
    "# --- Base line chart ---\n",
    "base = alt.Chart(melted_df).mark_line().encode(\n",
    "    x=alt.X('timestamp:T', title='Time'),\n",
    "    y=alt.Y('offset_value:Q', title='Offset Scaled Value'),\n",
    "    color=alt.Color('feature:N', title='Feature')\n",
    ").properties(width=500)\n",
    "\n",
    "# --- Points from latent selection (overlaid) ---\n",
    "highlighted_points = alt.Chart(melted_df).mark_circle(color='black', size=50).encode(\n",
    "    x='timestamp:T',\n",
    "    y='offset_value:Q',\n",
    "    tooltip=['feature:N', 'timestamp:T']\n",
    ").transform_filter(\n",
    "    latent_selection\n",
    ")\n",
    "\n",
    "# --- Upper (zoomed with brush, highlights added) ---\n",
    "upper = (base + highlighted_points).encode(\n",
    "    x=alt.X('timestamp:T', scale=alt.Scale(domain=brush))\n",
    ").properties(height=200)\n",
    "\n",
    "# --- Lower (overview with brush) ---\n",
    "lower = base.properties(height=60).add_params(brush)\n",
    "\n",
    "# --- Combine upper and lower ---\n",
    "time_series_chart = upper & lower\n",
    "\n",
    "# --- Latent heatmap with selection ---\n",
    "x_range = [int(df['latent_1'].min()) - 3, int(df['latent_1'].max()) + 3] \n",
    "y_range = [int(df['latent_2'].min()) - 3, int(df['latent_2'].max()) + 3]\n",
    "\n",
    "latent = alt.Chart(df).mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=150), scale=alt.Scale(domain=x_range), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=150), scale=alt.Scale(domain=y_range), title=\"Latent y\"),\n",
    "    color=alt.Color('label:N', scale=alt.Scale(scheme='spectral'), title='Density'),\n",
    "    tooltip=['label:N', 'timestamp:T', 'hour']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title=\"Latent Space (select region to highlight time)\"\n",
    ").add_params(\n",
    "    latent_selection\n",
    ").transform_filter(\n",
    "    brush\n",
    ").interactive()\n",
    "\n",
    "# --- Final layout ---\n",
    "latent | time_series_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477338c1-5f59-4ebd-acd0-b9a6f4ef5e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Combine all epoch dataframes into one DataFrame\n",
    "df_all = []\n",
    "\n",
    "for epoch, df_epoch in latent_dfs['Baseline'].items():\n",
    "    for method in ['pca_scl', 'umap_scl']:\n",
    "        df = df_epoch[method].copy()\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp format\n",
    "        df['epoch'] = epoch  # Add epoch column\n",
    "        df['method'] = method\n",
    "        df_all.append(df)\n",
    "\n",
    "df_combined = pd.concat(df_all, ignore_index=True)\n",
    "df_combined['hour_filter'] = df_combined['hour'].apply(lambda x: x - 12 if x >= 12 else x)\n",
    "\n",
    "# Step 2: Create selection slider\n",
    "epoch_slider = alt.binding_range(min=df_combined['epoch'].min(),\n",
    "                                 max=df_combined['epoch'].max(),\n",
    "                                 step=1,\n",
    "                                 name='Epoch: ')\n",
    "epoch_select = alt.selection_point (fields=['epoch'], bind=epoch_slider, value = 0)\n",
    "\n",
    "hour_options = [None] + sorted(df_combined['hour_filter'].unique().tolist())\n",
    "hour_selection = alt.selection_point(\n",
    "    name=\"Select Hour\", \n",
    "    fields=['hour_filter'], \n",
    "    bind=alt.binding_select(options=hour_options, name='Hour: '),\n",
    "    value=None\n",
    ")\n",
    "\n",
    "method_options = df_combined['method'].unique().tolist()\n",
    "method_selection = alt.selection_point(\n",
    "    name=\"Select method\", \n",
    "    fields=['method'], \n",
    "    bind=alt.binding_select(options=method_options, name='Method: '),\n",
    "    value=method_options[0]\n",
    ")\n",
    "\n",
    "# Step 3: Define heatmap chart\n",
    "heatmap = alt.Chart(df_combined).mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=100), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=100), title=\"Latent y\"),\n",
    "    color=alt.Color('label:N', scale=alt.Scale(scheme='spectral'), title='Label'),\n",
    "    tooltip=['label:N', 'epoch:Q', 'hour']\n",
    ").add_params(\n",
    "    epoch_select\n",
    ").add_params(\n",
    "    hour_selection\n",
    ").add_params(\n",
    "    method_selection\n",
    ").transform_filter(\n",
    "    epoch_select, hour_selection, method_selection\n",
    ").properties(\n",
    "    width=350,\n",
    "    height=350,\n",
    "    title=\"Interactive Latent Space Heatmap by Epoch\"\n",
    ").interactive()\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f8fc5-16f7-4270-ae21-621ae8acda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "with open(f'results/exp_latente_results_graeme_{agg_interval}_{window_size}_proto.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "    \n",
    "# Raw and transformed data\n",
    "transformed = results['Baseline']['dl'][0]['X'][0]       # shape: (200, 5)\n",
    "\n",
    "# Determine aggregation window\n",
    "agg_window = 3\n",
    "lenght_raw = transformed.shape[0] * agg_window\n",
    "scaler = MinMaxScaler()\n",
    "raw_scaled = scaler.fit_transform(client_A.iloc[:lenght_raw, 1:], (-1, 1))  # shape: (600, 5)\n",
    "\n",
    "# Time axes\n",
    "time_raw = np.arange(raw_scaled.shape[0])\n",
    "time_transformed = np.arange(transformed.shape[0]) * agg_window + agg_window // 2  # center of each window\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "offset = 2  # vertical offset to separate each feature\n",
    "\n",
    "for i in range(raw_scaled.shape[1]):\n",
    "    # Offset for clarity\n",
    "    plt.plot(time_raw, raw_scaled[:, i] + i * offset, color='lightgray', label=f'Raw Feature {i+1}' if i == 0 else \"\")\n",
    "    plt.plot(time_transformed, transformed[:, i] + i * offset, label=f'Transformed Feature {i+1}')\n",
    "\n",
    "plt.title('Raw vs Transformed (Aggregated) Multivariate Time Series')\n",
    "plt.xlabel('Time Step')\n",
    "plt.yticks([i * offset for i in range(raw_scaled.shape[1])],\n",
    "           [f'Feature {i+1}' for i in range(raw_scaled.shape[1])])\n",
    "plt.legend(bbox_to_anchor = (1,1))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163cb1aa-d7f3-4316-8aeb-5a0200ad7ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TsLeaks]",
   "language": "python",
   "name": "conda-env-TsLeaks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
