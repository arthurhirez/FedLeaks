{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:00:59.730327Z",
     "start_time": "2025-05-14T12:00:32.256009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "from datasets import Priv_NAMES as DATASET_NAMES\n",
    "from models import get_all_models\n",
    "\n",
    "from utils.Server import train, local_evaluate\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = ArgumentParser(description='You Only Need Me', allow_abbrev=False)\n",
    "    parser.add_argument('--device_id', type=int, default=0, help='The Device Id for Experiment')\n",
    "\n",
    "    # Communication - epochs\n",
    "    parser.add_argument('--communication_epoch', type=int, default=4,\n",
    "                        help='The Communication Epoch in Federated Learning')\n",
    "    parser.add_argument('--local_epoch', type=int, default=5, help='The Local Epoch for each Participant')\n",
    "\n",
    "    # Participants info\n",
    "    #TODO: LINK NUMBER OF PARTICIPANTS WITH SIMULATION\n",
    "    parser.add_argument('--parti_num', type=int, default=None, help='The Number for Participants. If \"None\" will be setted as the sum of values described in --domain')\n",
    "    parser.add_argument('--online_ratio', type=float, default=1, help='The Ratio for Online Clients')\n",
    "\n",
    "    # Data parameters\n",
    "    parser.add_argument('--dataset', type=str, default='fl_leaks', choices=DATASET_NAMES, help='Which scenario to perform experiments on.')\n",
    "    parser.add_argument('--experiment_id', type=str, default='PIPELINE_PYTHON', help='Which scenario the experiment is for.')\n",
    "    parser.add_argument('--domains', type=dict, default={\n",
    "                                                        'Graeme': 5,\n",
    "                                                        # 'Balerma': 3,\n",
    "                                                        },\n",
    "                        help='Domains and respective number of participants.')\n",
    "\n",
    "    ## Time series preprocessing\n",
    "    parser.add_argument('--interval_agg', type=int, default=3 * 60 ** 2,\n",
    "                        help='Agregation interval (seconds) of time series')\n",
    "    parser.add_argument('--window_size', type=int, default=200, help='Rolling window length')\n",
    "\n",
    "    # Model (AER) parameters\n",
    "    parser.add_argument('--input_size', type=int, default=5, help='Number of sensors')  #TODO adaptar\n",
    "    parser.add_argument('--output_size', type=int, default=5, help='Shape output - dense layer')\n",
    "    parser.add_argument('--lstm_units', type=int, default=30,\n",
    "                        help='Number of LSTM units (the latent space will have dimension 2 times bigger')\n",
    "\n",
    "    # Federated parameters\n",
    "    parser.add_argument('--model', type=str, default='fedavg', help='Federated Model name.', choices=get_all_models()) #fedavg\n",
    "\n",
    "    parser.add_argument('--structure', type=str, default='homogeneity')\n",
    "\n",
    "    parser.add_argument('--pri_aug', type=str, default='weak',  # weak strong\n",
    "                        help='Augmentation for Private Data')\n",
    "    parser.add_argument('--learning_decay', type=bool, default=False, help='The Option for Learning Rate Decay')\n",
    "    parser.add_argument('--averaging', type=str, default='weight', help='The Option for averaging strategy')\n",
    "\n",
    "    parser.add_argument('--infoNCET', type=float, default=0.02, help='The InfoNCE temperature')\n",
    "    parser.add_argument('--T', type=float, default=0.05, help='The Knowledge distillation temperature')\n",
    "    parser.add_argument('--weight', type=int, default=1, help='The Weigth for the distillation loss')\n",
    "\n",
    "    # torch.set_num_threads(4)\n",
    "    # def add_management_args(parser: ArgumentParser) -> None:\n",
    "    #     parser.add_argument('--csv_log', action='store_true',\n",
    "    #                         help='Enable csv logging',default=False)\n",
    "    #\n",
    "    # add_management_args(parser)\n",
    "    #\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    if args.parti_num is None:\n",
    "        args.parti_num = sum(args.domains.values())\n",
    "    #\n",
    "    # best = best_args[args.dataset][args.model]\n",
    "    #\n",
    "    # for key, value in best.items():\n",
    "    #     setattr(args, key, value)\n",
    "    #\n",
    "    # if args.seed is not None:\n",
    "    #     set_random_seed(args.seed)\n",
    "\n",
    "    return args"
   ],
   "id": "ec019368db80ff3c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:00:59.765034Z",
     "start_time": "2025-05-14T12:00:59.755448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets.utils import FederatedDataset\n",
    "from models.utils.federated_model import FederatedModel\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "def train(model: FederatedModel, private_dataset: FederatedDataset, scenario: str,\n",
    "          args: Namespace) -> None:\n",
    "    # if args.csv_log:\n",
    "    #     csv_writer = CsvWriter(args, private_dataset)\n",
    "\n",
    "    priv_train_loaders = private_dataset.get_data_loaders(scenario=scenario)\n",
    "\n",
    "    private_train_loaders = []\n",
    "    for loader in priv_train_loaders:\n",
    "        private_train_loaders.append(loader['X'])\n",
    "\n",
    "    model.trainloaders = private_train_loaders  # TODO REVER ISSO!!!\n",
    "\n",
    "    if hasattr(model, 'ini'):\n",
    "        model.ini()\n",
    "\n",
    "\n",
    "    Epoch = args.communication_epoch\n",
    "    for epoch_index in range(Epoch):\n",
    "        model.epoch_index = epoch_index\n",
    "        if hasattr(model, 'loc_update'):\n",
    "            epoch_loc_loss_dict = model.loc_update(private_train_loaders)\n",
    "\n",
    "        print(10 * '**--')\n",
    "        print('SEM AGREGAÇÃO')\n",
    "\n",
    "        aux_latent = local_evaluate(model=model, train_dl=priv_train_loaders, private_dataset=private_dataset,\n",
    "                                    group_detections=False)\n",
    "\n",
    "        # print(10*'**--')\n",
    "        # print('COM AGREGAÇÃO')\n",
    "        # local_evaluate(model = model, train_dl = priv_train_loaders[1], df_results = df_results, group_detections = True)\n",
    "\n",
    "    return priv_train_loaders, aux_latent\n"
   ],
   "id": "5fddf4e3e1edca80",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:49.345852Z",
     "start_time": "2025-05-14T12:00:59.783106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import get_private_dataset\n",
    "from models import get_model\n",
    "\n",
    "args = parse_args()\n",
    "\n",
    "results = {}\n",
    "\n",
    "priv_dataset = get_private_dataset(args)\n",
    "\n",
    "backbones_list = priv_dataset.get_backbone(parti_num=args.parti_num,\n",
    "                                           names_list=None,\n",
    "                                           n_series=args.input_size)\n",
    "\n",
    "model = get_model(backbones_list, args, priv_dataset)\n",
    "\n",
    "# priv_dataset.EXP_ID = ['Drift_PIPELINE_ALERNATIVE']\n",
    "# priv_dataset.DOMAINS_LIST = ['Balerma']\n",
    "\n",
    "priv_train_loaders, aux_latent = train(model=model,\n",
    "                                       private_dataset=priv_dataset,\n",
    "                                       scenario='AutoScenario_1',\n",
    "                                       args=args)"
   ],
   "id": "c83c796636db5737",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training client 4\n",
      "Epoch 1/5 - Loss: 5.2863\n",
      "Epoch 2/5 - Loss: 4.6354\n",
      "Epoch 3/5 - Loss: 4.3699\n",
      "Epoch 4/5 - Loss: 4.0852\n",
      "Epoch 5/5 - Loss: 3.8697\n",
      "epochs: 5 / total 5\n",
      "Training client 1\n",
      "Epoch 1/5 - Loss: 6.3705\n",
      "Epoch 2/5 - Loss: 4.1731\n",
      "Epoch 3/5 - Loss: 4.0533\n",
      "Epoch 4/5 - Loss: 3.9643\n",
      "Epoch 5/5 - Loss: 3.8599\n",
      "epochs: 5 / total 5\n",
      "Training client 2\n",
      "Epoch 1/5 - Loss: 5.7498\n",
      "Epoch 2/5 - Loss: 5.3386\n",
      "Epoch 3/5 - Loss: 5.0167\n",
      "Epoch 4/5 - Loss: 4.6497\n",
      "Epoch 5/5 - Loss: 4.2882\n",
      "epochs: 5 / total 5\n",
      "Training client 3\n",
      "Epoch 1/5 - Loss: 4.9732\n",
      "Epoch 2/5 - Loss: 4.4394\n",
      "Epoch 3/5 - Loss: 4.2137\n",
      "Epoch 4/5 - Loss: 3.9712\n",
      "Epoch 5/5 - Loss: 3.7469\n",
      "epochs: 5 / total 5\n",
      "Training client 0\n",
      "Epoch 1/5 - Loss: 4.0175\n",
      "Epoch 2/5 - Loss: 3.6365\n",
      "Epoch 3/5 - Loss: 3.4073\n",
      "Epoch 4/5 - Loss: 3.1984\n",
      "Epoch 5/5 - Loss: 3.0768\n",
      "epochs: 5 / total 5\n",
      "**--**--**--**--**--**--**--**--**--**--\n",
      "SEM AGREGAÇÃO\n",
      "Acc: 0.7604\tPrec: 0.1139\tRec: 0.0659\tF1: 0.0835\n",
      "Acc: 0.7911\tPrec: 0.4360\tRec: 0.8898\tF1: 0.5853\n",
      "Acc: 0.7744\tPrec: 0.0000\tRec: 0.0000\tF1: 0.0000\n",
      "Acc: 0.7429\tPrec: 0.3032\tRec: 0.4251\tF1: 0.3539\n",
      "Acc: 0.7917\tPrec: 0.4412\tRec: 0.9665\tF1: 0.6059\n",
      "Training client 2\n",
      "Epoch 1/5 - Loss: 5.9786\n",
      "Epoch 2/5 - Loss: 5.3966\n",
      "Epoch 3/5 - Loss: 5.2018\n",
      "Epoch 4/5 - Loss: 4.9603\n",
      "Epoch 5/5 - Loss: 4.7521\n",
      "epochs: 5 / total 10\n",
      "Training client 4\n",
      "Epoch 1/5 - Loss: 5.3117\n",
      "Epoch 2/5 - Loss: 4.6677\n",
      "Epoch 3/5 - Loss: 4.5407\n",
      "Epoch 4/5 - Loss: 4.3411\n",
      "Epoch 5/5 - Loss: 4.1663\n",
      "epochs: 5 / total 10\n",
      "Training client 0\n",
      "Epoch 1/5 - Loss: 3.9957\n",
      "Epoch 2/5 - Loss: 3.6440\n",
      "Epoch 3/5 - Loss: 3.6006\n",
      "Epoch 4/5 - Loss: 3.5167\n",
      "Epoch 5/5 - Loss: 3.4422\n",
      "epochs: 5 / total 10\n",
      "Training client 1\n",
      "Epoch 1/5 - Loss: 8.2667\n",
      "Epoch 2/5 - Loss: 4.3298\n",
      "Epoch 3/5 - Loss: 4.0245\n",
      "Epoch 4/5 - Loss: 3.9695\n",
      "Epoch 5/5 - Loss: 3.9044\n",
      "epochs: 5 / total 10\n",
      "Training client 3\n",
      "Epoch 1/5 - Loss: 5.3680\n",
      "Epoch 2/5 - Loss: 4.5422\n",
      "Epoch 3/5 - Loss: 4.4764\n",
      "Epoch 4/5 - Loss: 4.3870\n",
      "Epoch 5/5 - Loss: 4.2215\n",
      "epochs: 5 / total 10\n",
      "**--**--**--**--**--**--**--**--**--**--\n",
      "SEM AGREGAÇÃO\n",
      "Acc: 0.8278\tPrec: 0.4776\tRec: 0.4204\tF1: 0.4471\n",
      "Acc: 0.7911\tPrec: 0.4360\tRec: 0.8898\tF1: 0.5853\n",
      "Acc: 0.7988\tPrec: 0.3839\tRec: 0.3545\tF1: 0.3686\n",
      "Acc: 0.7921\tPrec: 0.3836\tRec: 0.4204\tF1: 0.4011\n",
      "Acc: 0.7959\tPrec: 0.4477\tRec: 0.9952\tF1: 0.6176\n",
      "Training client 3\n",
      "Epoch 1/5 - Loss: 4.6052\n",
      "Epoch 2/5 - Loss: 4.2853\n",
      "Epoch 3/5 - Loss: 3.9986\n",
      "Epoch 4/5 - Loss: 3.7733\n",
      "Epoch 5/5 - Loss: 3.4271\n",
      "epochs: 5 / total 15\n",
      "Training client 0\n",
      "Epoch 1/5 - Loss: 3.6844\n",
      "Epoch 2/5 - Loss: 3.5347\n",
      "Epoch 3/5 - Loss: 3.2980\n",
      "Epoch 4/5 - Loss: 3.1746\n",
      "Epoch 5/5 - Loss: 2.9004\n",
      "epochs: 5 / total 15\n",
      "Training client 1\n",
      "Epoch 1/5 - Loss: 5.6417\n",
      "Epoch 2/5 - Loss: 3.9816\n",
      "Epoch 3/5 - Loss: 3.8467\n",
      "Epoch 4/5 - Loss: 3.7295\n",
      "Epoch 5/5 - Loss: 3.6196\n",
      "epochs: 5 / total 15\n",
      "Training client 4\n",
      "Epoch 1/5 - Loss: 4.6634\n",
      "Epoch 2/5 - Loss: 4.2201\n",
      "Epoch 3/5 - Loss: 3.9515\n",
      "Epoch 4/5 - Loss: 3.5234\n",
      "Epoch 5/5 - Loss: 2.9531\n",
      "epochs: 5 / total 15\n",
      "Training client 2\n",
      "Epoch 1/5 - Loss: 5.5042\n",
      "Epoch 2/5 - Loss: 4.9514\n",
      "Epoch 3/5 - Loss: 4.5440\n",
      "Epoch 4/5 - Loss: 3.8964\n",
      "Epoch 5/5 - Loss: 3.3356\n",
      "epochs: 5 / total 15\n",
      "**--**--**--**--**--**--**--**--**--**--\n",
      "SEM AGREGAÇÃO\n",
      "Acc: 0.7985\tPrec: 0.3984\tRec: 0.4251\tF1: 0.4114\n",
      "Acc: 0.7653\tPrec: 0.3707\tRec: 0.5976\tF1: 0.4576\n",
      "Acc: 0.7941\tPrec: 0.3641\tRec: 0.3257\tF1: 0.3439\n",
      "Acc: 0.8221\tPrec: 0.4708\tRec: 0.5976\tF1: 0.5266\n",
      "Acc: 0.8054\tPrec: 0.4596\tRec: 0.9952\tF1: 0.6288\n",
      "Training client 0\n",
      "Epoch 1/5 - Loss: 3.2289\n",
      "Epoch 2/5 - Loss: 2.5651\n",
      "Epoch 3/5 - Loss: 2.3236\n",
      "Epoch 4/5 - Loss: 2.2429\n",
      "Epoch 5/5 - Loss: 2.2181\n",
      "epochs: 5 / total 20\n",
      "Training client 3\n",
      "Epoch 1/5 - Loss: 4.1442\n",
      "Epoch 2/5 - Loss: 3.4066\n",
      "Epoch 3/5 - Loss: 2.9007\n",
      "Epoch 4/5 - Loss: 2.7082\n",
      "Epoch 5/5 - Loss: 2.6206\n",
      "epochs: 5 / total 20\n",
      "Training client 2\n",
      "Epoch 1/5 - Loss: 4.6479\n",
      "Epoch 2/5 - Loss: 3.5453\n",
      "Epoch 3/5 - Loss: 3.1865\n",
      "Epoch 4/5 - Loss: 3.0923\n",
      "Epoch 5/5 - Loss: 2.9871\n",
      "epochs: 5 / total 20\n",
      "Training client 4\n",
      "Epoch 1/5 - Loss: 3.6278\n",
      "Epoch 2/5 - Loss: 2.8846\n",
      "Epoch 3/5 - Loss: 2.6896\n",
      "Epoch 4/5 - Loss: 2.6363\n",
      "Epoch 5/5 - Loss: 2.5655\n",
      "epochs: 5 / total 20\n",
      "Training client 1\n",
      "Epoch 1/5 - Loss: 4.8322\n",
      "Epoch 2/5 - Loss: 3.6036\n",
      "Epoch 3/5 - Loss: 3.3408\n",
      "Epoch 4/5 - Loss: 3.0642\n",
      "Epoch 5/5 - Loss: 2.8688\n",
      "epochs: 5 / total 20\n",
      "**--**--**--**--**--**--**--**--**--**--\n",
      "SEM AGREGAÇÃO\n",
      "Acc: 0.8121\tPrec: 0.4557\tRec: 0.6898\tF1: 0.5488\n",
      "Acc: 0.8223\tPrec: 0.4768\tRec: 0.7497\tF1: 0.5829\n",
      "Acc: 0.7187\tPrec: 0.2919\tRec: 0.4898\tF1: 0.3658\n",
      "Acc: 0.7792\tPrec: 0.4028\tRec: 0.6898\tF1: 0.5086\n",
      "Acc: 0.7592\tPrec: 0.3715\tRec: 0.6563\tF1: 0.4745\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:50.048416Z",
     "start_time": "2025-05-14T12:09:50.031807Z"
    }
   },
   "cell_type": "code",
   "source": "priv_train_loaders[0].keys()",
   "id": "7f14c4aef4b7145e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_raw', 'X', 'X_norm', 'index', 'y', 'X_index', 'y_index', 'ry_hat', 'y_hat', 'fy_hat', 'x_lat', 'errors', 'results', 'anomalies', 'metrics'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:50.289622Z",
     "start_time": "2025-05-14T12:09:50.264752Z"
    }
   },
   "cell_type": "code",
   "source": "dl = model.nets_list[0].create_dataloader(X = priv_train_loaders[0]['X'])",
   "id": "a536db17617feb3b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:51.894709Z",
     "start_time": "2025-05-14T12:09:50.337827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for d in b:\n",
    "    print(d.shape)"
   ],
   "id": "cc6149d82cc8128f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m \u001B[43mb\u001B[49m:\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(d\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'b' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(dl) * 4",
   "id": "c80dc90b3350f87b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(priv_train_loaders[0]['X_index'])",
   "id": "5a55fdea752815c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:42:00.354823Z",
     "start_time": "2025-05-14T14:42:00.251225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nets_list = priv_dataset.get_backbone(parti_num=args.parti_num,\n",
    "                                           names_list=None,\n",
    "                                           n_series=args.input_size)"
   ],
   "id": "531a9672d4721ac",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:11:31.982876Z",
     "start_time": "2025-05-14T12:11:31.956951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def agg_func(protos):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "\n",
    "    for [label, proto_list] in protos.items():\n",
    "        if len(proto_list) > 1:\n",
    "            proto = 0 * proto_list[0].data\n",
    "            for i in proto_list:\n",
    "                proto += i.data\n",
    "            protos[label] = proto / len(proto_list)\n",
    "        else:\n",
    "            protos[label] = proto_list[0]\n",
    "\n",
    "    return protos\n",
    "\n",
    "\n",
    "def calculate_infonce(f_now, f_pos, f_neg):\n",
    "    device = 'cpu'\n",
    "    f_proto = torch.cat((f_pos, f_neg), dim=0)\n",
    "    l = torch.cosine_similarity(f_now, f_proto, dim=1)\n",
    "    l = l / 0.02\n",
    "\n",
    "    exp_l = torch.exp(l)\n",
    "    exp_l = exp_l.view(1, -1)\n",
    "    pos_mask = [1 for _ in range(f_pos.shape[0])] + [0 for _ in range(f_neg.shape[0])]\n",
    "    pos_mask = torch.tensor(pos_mask, dtype=torch.float).to(device)\n",
    "    pos_mask = pos_mask.view(1, -1)\n",
    "    # pos_l = torch.einsum('nc,ck->nk', [exp_l, pos_mask])\n",
    "    pos_l = exp_l * pos_mask\n",
    "    sum_pos_l = pos_l.sum(1)\n",
    "    sum_exp_l = exp_l.sum(1)\n",
    "    infonce_loss = -torch.log(sum_pos_l / sum_exp_l)\n",
    "    return infonce_loss\n",
    "\n",
    "def hierarchical_info_loss(f_now, label, all_f, mean_f, all_global_protos_keys):\n",
    "    device = 'cpu'\n",
    "    print(\"\\n=== DEBUGGING INFO ===\")\n",
    "\n",
    "    # Print type and shape of all_f elements\n",
    "    print(\"Type of all_f:\", type(all_f))\n",
    "    if isinstance(all_f, list):\n",
    "        print(f\"all_f contains {len(all_f)} elements.\")\n",
    "        for i, item in enumerate(all_f):\n",
    "            print(f\"Element {i}: Type={type(item)}, Shape={item.shape if hasattr(item, 'shape') else 'N/A'}\")\n",
    "    elif isinstance(all_f, torch.Tensor):\n",
    "        print(f\"all_f is a tensor with shape: {all_f.shape}\")\n",
    "    elif isinstance(all_f, np.ndarray):\n",
    "        print(f\"all_f is a numpy array with shape: {all_f.shape}\")\n",
    "\n",
    "    # Print type and shape of all_global_protos_keys\n",
    "    print(\"\\nType of all_global_protos_keys:\", type(all_global_protos_keys))\n",
    "    if isinstance(all_global_protos_keys, torch.Tensor):\n",
    "        print(f\"Shape of all_global_protos_keys torch.Tensor: {all_global_protos_keys.shape}\")\n",
    "    elif isinstance(all_global_protos_keys, np.ndarray):\n",
    "        print(f\"Shape of all_global_protos_keys np.array: {all_global_protos_keys.shape}\")\n",
    "\n",
    "    # Print label info\n",
    "    print(\"\\nType of label:\", type(label))\n",
    "    if isinstance(label, torch.Tensor):\n",
    "        print(f\"Label torch.Tensor value: {label} {label.item()}, Shape: {label.shape}\")\n",
    "    elif isinstance(label, np.ndarray):\n",
    "        print(f\"Label np.ndarray value: {label}, Shape: {label.shape}\")\n",
    "\n",
    "\n",
    "    print(\"\\nType of meanf:\", type(mean_f))\n",
    "\n",
    "    print(f\"meanf torch.Tensor value: Shape: {len(mean_f)}\")\n",
    "\n",
    "\n",
    "    # Check boolean indexing\n",
    "    try:\n",
    "        indices = (all_global_protos_keys == label.item()).nonzero()\n",
    "        print(f\"\\nNumber of matching indices: {len(indices)}\")\n",
    "        if len(indices) > 0:\n",
    "            print(f\"First matching index: {indices[0]}\")\n",
    "            print(f\"Indexes: {indices}\")\n",
    "    except Exception as e:\n",
    "        print(\"\\nError while checking indices:\", e)\n",
    "\n",
    "    print(\"\\n======================\\n\")\n",
    "\n",
    "    f_pos = np.array(all_f)[all_global_protos_keys == label.item()][0].to(device)\n",
    "    f_neg = torch.cat(list(np.array(all_f)[all_global_protos_keys != label.item()])).to(device)\n",
    "\n",
    "    f_pos = [f for i, f in enumerate(all_f) if all_global_protos_keys[i] == label.item()][0].to(device)\n",
    "    f_neg = torch.cat([f for i, f in enumerate(all_f) if all_global_protos_keys[i] != label.item()]).to(device)\n",
    "    xi_info_loss = calculate_infonce(f_now, f_pos, f_neg)\n",
    "\n",
    "\n",
    "    # mean_f_pos = np.array(mean_f)[all_global_protos_keys == label.item()][0].to(device)\n",
    "    mean_f_pos = [f for i, f in enumerate(all_f) if all_global_protos_keys[i] == label.item()][0].to(device)\n",
    "    mean_f_pos = mean_f_pos.view(1, -1)\n",
    "    # COMENTAR AQUI AQUI O DEBUG\n",
    "\n",
    "    f_idx = np.where(all_global_protos_keys == label.item())[0][0]\n",
    "    f_pos = all_f[f_idx].to(device)\n",
    "    f_neg = torch.cat([f for i, f in enumerate(all_f) if i != f_idx]).to(device)\n",
    "    xi_info_loss = calculate_infonce(f_now, f_pos, f_neg)\n",
    "\n",
    "    mean_f_pos = mean_f[f_idx].to(device)\n",
    "\n",
    "    # mean_f_neg = torch.cat(list(np.array(mean_f)[all_global_protos_keys != label.item()]), dim=0).to(device)\n",
    "    # mean_f_neg = mean_f_neg.view(9, -1)\n",
    "\n",
    "    loss_mse = nn.MSELoss()\n",
    "    cu_info_loss = loss_mse(f_now, mean_f_pos)\n",
    "\n",
    "    hierar_info_loss = xi_info_loss + cu_info_loss\n",
    "    return hierar_info_loss"
   ],
   "id": "14ee13e838f14ab3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:51.990326100Z",
     "start_time": "2025-05-13T16:07:20.097063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "# from utils.args import *\n",
    "from models.utils.federated_model import FederatedModel\n",
    "import torch\n",
    "from utils.finch import FINCH\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "global_protos = {} # lista #classes prototipos globais\n",
    "local_protos = {} # dict #clientes : lista #classes prototipos locais\n",
    "local_epoch = 3\n",
    "\n",
    "net = nets_list[0]\n",
    "train_loader = priv_train_loaders[0]['X']\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "net = net.to(device)\n",
    "optimizer = net.optimizer_class(net.parameters(), lr=net.learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "\n",
    "if len(global_protos) != 0:\n",
    "    all_global_protos_keys = np.array(list(global_protos.keys()))\n",
    "    all_f = []\n",
    "    mean_f = []\n",
    "    for protos_key in all_global_protos_keys:\n",
    "        temp_f = global_protos[protos_key]\n",
    "        temp_f = torch.cat(temp_f, dim=0).to(device)\n",
    "        all_f.append(temp_f.cpu())\n",
    "        mean_f.append(torch.mean(temp_f, dim=0).cpu())\n",
    "    all_f = [item.detach() for item in all_f]\n",
    "    mean_f = [item.detach() for item in mean_f]\n",
    "\n",
    "iterator = tqdm(range(local_epoch))\n",
    "for iter in iterator:\n",
    "    agg_protos_label = {}\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        f = net.features(images)\n",
    "        outputs = net.classifier(f)\n",
    "\n",
    "        lossCE = criterion(outputs, labels)\n",
    "\n",
    "        if len(global_protos) == 0:\n",
    "            loss_InfoNCE = 0 * lossCE\n",
    "        else:\n",
    "            i = 0\n",
    "            loss_InfoNCE = None\n",
    "\n",
    "            for label in labels:\n",
    "                if label.item() in global_protos.keys():\n",
    "                    f_now = f[i].unsqueeze(0)\n",
    "                    loss_instance = hierarchical_info_loss(f_now, label, all_f, mean_f, all_global_protos_keys)\n",
    "\n",
    "                    if loss_InfoNCE is None:\n",
    "                        loss_InfoNCE = loss_instance\n",
    "                    else:\n",
    "                        loss_InfoNCE += loss_instance\n",
    "                i += 1\n",
    "            loss_InfoNCE = loss_InfoNCE / i\n",
    "        loss_InfoNCE = loss_InfoNCE\n",
    "\n",
    "        loss = lossCE + loss_InfoNCE\n",
    "        loss.backward()\n",
    "        iterator.desc = \"Local Pariticipant %d CE = %0.3f,InfoNCE = %0.3f\" % (lossCE, loss_InfoNCE)\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter == local_epoch - 1:\n",
    "            for i in range(len(labels)):\n",
    "                if labels[i].item() in agg_protos_label:\n",
    "                    agg_protos_label[labels[i].item()].append(f[i, :])\n",
    "                else:\n",
    "                    agg_protos_label[labels[i].item()] = [f[i, :]]\n",
    "\n",
    "agg_protos = agg_func(agg_protos_label)\n",
    "\n",
    "# # self.local_history[index].append(copy.deepcopy(agg_protos))\n",
    "# local_history[index].append({\n",
    "#                                 key: tensor.detach().cpu().numpy()\n",
    "#                                 for key, tensor in agg_protos.items()\n",
    "#                             })\n",
    "#\n",
    "# local_protos[index] = agg_protos"
   ],
   "id": "4d60c0b0b1dea12c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 41\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28miter\u001B[39m \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[0;32m     40\u001B[0m     agg_protos_label \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (images, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m     42\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     44\u001B[0m         images \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:11:55.180977Z",
     "start_time": "2025-05-14T12:11:55.149678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "labels_df = priv_dataset.get_labels()['Graeme']['AutoScenario_1']\n",
    "labels_dl = labels_df[labels_df['timestamp'].isin(priv_train_loaders[0]['X_index'])]\n",
    "labels_dl = np.array(labels_dl['label'])\n",
    "\n",
    "labels_dl.shape"
   ],
   "id": "40a7b5fe64bf9d7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1481,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:12:01.053066Z",
     "start_time": "2025-05-14T12:12:01.021819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.Server import find_anomalies, evaluate_predictions\n",
    "import pandas as pd\n",
    "from backbone.AER import score_anomalies\n",
    "\n",
    "def process_anomalies_proto(dl, df_anomalies, labels_df):\n",
    "    labels_df = labels_df.copy()\n",
    "    labels_df['timestamp'] = labels_df['timestamp'].astype(float)\n",
    "    y_pred = np.zeros_like(labels_df['timestamp'], dtype=int)\n",
    "\n",
    "    for _, row in df_anomalies.iterrows():\n",
    "        mask = (labels_df['timestamp'] >= row['start']) & (labels_df['timestamp'] <= row['end'])\n",
    "        y_pred[mask] = 1\n",
    "\n",
    "    labels_df['y_pred'] = y_pred\n",
    "    dl['results'] = labels_df\n",
    "    dl['anomalies'] = df_anomalies\n",
    "\n",
    "    if dl.get('metrics') is None:\n",
    "        dl['metrics'] = []\n",
    "\n",
    "    dl['metrics'].append(evaluate_predictions(labels_df))\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "def compute_errors_proto(X, ry_hat, y_hat, fy_hat):\n",
    "\n",
    "\n",
    "    # Convert to numpy if they're PyTorch tensors\n",
    "    if hasattr(X, 'detach'):\n",
    "        X = X.detach().cpu().numpy()\n",
    "    if hasattr(ry_hat, 'detach'):\n",
    "        ry_hat = ry_hat.detach().cpu().numpy()\n",
    "    if hasattr(y_hat, 'detach'):\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "    if hasattr(fy_hat, 'detach'):\n",
    "        fy_hat = fy_hat.detach().cpu().numpy()\n",
    "\n",
    "    input_window = 200\n",
    "    aux_errors = []\n",
    "\n",
    "    for channel in range(X.shape[2]):\n",
    "        errors = score_anomalies(\n",
    "            y = X[:, :, channel].reshape(-1, input_window, 1),\n",
    "            ry_hat = ry_hat[:, channel].reshape(-1, 1),\n",
    "            y_hat = y_hat[:, :, channel].reshape(-1, input_window - 2, 1),\n",
    "            fy_hat = fy_hat[:, channel].reshape(-1, 1),\n",
    "            smoothing_window = 0.01,\n",
    "            smooth = True,\n",
    "            mask = True,\n",
    "            comb = 'mult',\n",
    "            lambda_rec = 0.5,\n",
    "            rec_error_type = \"dtw\"\n",
    "        )\n",
    "        aux_errors.append(errors)\n",
    "\n",
    "    return aux_errors\n",
    "\n",
    "\n",
    "def local_evaluate_proto(net,\n",
    "                   dataloader,\n",
    "                   labels) -> list:\n",
    "\n",
    "    dataloader['ry_hat'], dataloader['y_hat'], dataloader['fy_hat'], dataloader['x_lat'] = net.predict(dataloader['X'])\n",
    "    dataloader['errors'] = compute_errors_proto(dataloader['X'], dataloader['ry_hat'], dataloader['y_hat'], dataloader['fy_hat'])\n",
    "\n",
    "    aux_anomaly = []\n",
    "    for error in dataloader['errors']:\n",
    "        detections = find_anomalies(\n",
    "            errors=error,\n",
    "            index=dataloader['index'],\n",
    "            window_size_portion=0.35,\n",
    "            window_step_size_portion=0.10,\n",
    "            fixed_threshold=True,\n",
    "            inverse=True,\n",
    "            anomaly_padding=50,\n",
    "            lower_threshold=True\n",
    "        )\n",
    "        if len(detections):\n",
    "            aux_anomaly.append(detections)\n",
    "\n",
    "\n",
    "    df_anomalies = pd.DataFrame(np.vstack(aux_anomaly), columns=['start', 'end', 'severity'])\n",
    "\n",
    "    y_pred = process_anomalies_proto(dataloader, df_anomalies, labels)\n",
    "\n",
    "    return y_pred, dataloader['x_lat'].copy()"
   ],
   "id": "69741e1590f17590",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:43:09.287026Z",
     "start_time": "2025-05-14T14:42:50.157576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "# from utils.args import *\n",
    "from models.utils.federated_model import FederatedModel\n",
    "import torch\n",
    "from utils.finch import FINCH\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "global_protos = {} # lista #classes prototipos globais\n",
    "local_protos = {} # dict #clientes : lista #classes prototipos locais\n",
    "local_epoch = 3\n",
    "\n",
    "net = nets_list[0]\n",
    "train_loader = priv_train_loaders[0]['X']\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "net = net.to(device)\n",
    "optimizer = net.optimizer_class(net.parameters(), lr=net.learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device)\n",
    "\n",
    "if len(global_protos) != 0:\n",
    "    all_global_protos_keys = np.array(list(global_protos.keys()))\n",
    "    all_f = []\n",
    "    mean_f = []\n",
    "    for protos_key in all_global_protos_keys:\n",
    "        temp_f = global_protos[protos_key]\n",
    "        temp_f = torch.cat(temp_f, dim=0).to(device)\n",
    "        all_f.append(temp_f.cpu())\n",
    "        mean_f.append(torch.mean(temp_f, dim=0).cpu())\n",
    "    all_f = [item.detach() for item in all_f]\n",
    "    mean_f = [item.detach() for item in mean_f]\n",
    "\n",
    "iterator = tqdm(range(local_epoch))\n",
    "for iter in iterator:\n",
    "    agg_protos_label = {}\n",
    "    # for batch_idx, (images, labels) in enumerate(zip(train_loader, labels_dl)):\n",
    "    #     images = images.reshape(-1, images.shape[0], images.shape[1])\n",
    "    images = priv_train_loaders[0]\n",
    "    labels = labels_dl\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # images = images.to(device)\n",
    "\n",
    "    model_outputs, f = local_evaluate_proto(net=net, dataloader=images, labels=labels_df)\n",
    "\n",
    "    # Get matching predictions as tensor (not numpy!)\n",
    "    # Make sure this slicing doesn't detach gradients\n",
    "    mask = labels_df['timestamp'].isin(priv_train_loaders[0]['X_index'])\n",
    "    outputs = model_outputs[mask.values]  # assuming model_outputs is a tensor\n",
    "\n",
    "    # Ensure labels are tensors and on the same device\n",
    "    labels_tensor = torch.tensor(labels_df[mask]['label'].values, dtype=torch.long)\n",
    "\n",
    "    # lossCE = criterion(outputs, labels_tensor)\n",
    "\n",
    "\n",
    "    if len(global_protos) == 0:\n",
    "        loss_InfoNCE = 0 #* lossCE\n",
    "    else:\n",
    "        i = 0\n",
    "        loss_InfoNCE = None\n",
    "\n",
    "        for label in labels:\n",
    "            if label.item() in global_protos.keys():\n",
    "                f_now = f[i].unsqueeze(0)\n",
    "                loss_instance = hierarchical_info_loss(f_now, label, all_f, mean_f, all_global_protos_keys)\n",
    "\n",
    "                if loss_InfoNCE is None:\n",
    "                    loss_InfoNCE = loss_instance\n",
    "                else:\n",
    "                    loss_InfoNCE += loss_instance\n",
    "            i += 1\n",
    "        loss_InfoNCE = loss_InfoNCE / i\n",
    "    loss_InfoNCE = loss_InfoNCE\n",
    "\n",
    "    # loss = lossCE + loss_InfoNCE\n",
    "    # loss.backward()\n",
    "    iterator.desc = \"Local Pariticipant,InfoNCE = %0.3f\" % (loss_InfoNCE)\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter == local_epoch - 1:\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i].item() in agg_protos_label:\n",
    "                agg_protos_label[labels[i].item()].append(f[i, :])\n",
    "            else:\n",
    "                agg_protos_label[labels[i].item()] = [f[i, :]]\n",
    "\n",
    "agg_protos = agg_func(agg_protos_label)\n",
    "\n",
    "# # self.local_history[index].append(copy.deepcopy(agg_protos))\n",
    "# local_history[index].append({\n",
    "#                                 key: tensor.detach().cpu().numpy()\n",
    "#                                 for key, tensor in agg_protos.items()\n",
    "#                             })\n",
    "#\n",
    "# local_protos[index] = agg_protos"
   ],
   "id": "2028c21b30fd89f4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Pariticipant,InfoNCE = 0.000:  33%|███▎      | 1/3 [00:07<00:14,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.7574\tPrec: 0.2104\tRec: 0.1689\tF1: 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Pariticipant,InfoNCE = 0.000:  67%|██████▋   | 2/3 [00:13<00:06,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.7574\tPrec: 0.2104\tRec: 0.1689\tF1: 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Local Pariticipant,InfoNCE = 0.000: 100%|██████████| 3/3 [00:19<00:00,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.7574\tPrec: 0.2104\tRec: 0.1689\tF1: 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'memoryview'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 94\u001B[0m\n\u001B[0;32m     91\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m                 agg_protos_label[labels[i]\u001B[38;5;241m.\u001B[39mitem()] \u001B[38;5;241m=\u001B[39m [f[i, :]]\n\u001B[1;32m---> 94\u001B[0m agg_protos \u001B[38;5;241m=\u001B[39m \u001B[43magg_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43magg_protos_label\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 8\u001B[0m, in \u001B[0;36magg_func\u001B[1;34m(protos)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m [label, proto_list] \u001B[38;5;129;01min\u001B[39;00m protos\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(proto_list) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m----> 8\u001B[0m         proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mproto_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m proto_list:\n\u001B[0;32m     10\u001B[0m             proto \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m i\u001B[38;5;241m.\u001B[39mdata\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for *: 'int' and 'memoryview'"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:44:40.803969Z",
     "start_time": "2025-05-14T14:44:40.788336Z"
    }
   },
   "cell_type": "code",
   "source": "len(agg_protos_label[0]), len(agg_protos_label[1])",
   "id": "aaa50798c844c3d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1219, 262)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:51.993326300Z",
     "start_time": "2025-05-13T17:24:41.396065Z"
    }
   },
   "cell_type": "code",
   "source": "priv_train_loaders[0].keys()",
   "id": "7f4e819c75ede889",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_raw', 'X', 'X_norm', 'index', 'y', 'X_index', 'y_index', 'ry_hat', 'y_hat', 'fy_hat', 'x_lat', 'errors', 'results', 'anomalies', 'metrics'])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:51.993326300Z",
     "start_time": "2025-05-13T17:41:07.835565Z"
    }
   },
   "cell_type": "code",
   "source": "labels.shape, outputs.shape, labels_df.shape",
   "id": "3a127ae9f9fa30aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1481]), torch.Size([5041]), (5041, 2))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:51.994326900Z",
     "start_time": "2025-05-13T17:43:33.775576Z"
    }
   },
   "cell_type": "code",
   "source": "priv_train_loaders[0]['X_index'].shape",
   "id": "acfd00c0a26b846e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1481,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:51.994326900Z",
     "start_time": "2025-05-13T17:36:46.207065Z"
    }
   },
   "cell_type": "code",
   "source": "outputs",
   "id": "fc31c86d252ee631",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T12:09:51.995599Z",
     "start_time": "2025-05-13T17:32:01.045703Z"
    }
   },
   "cell_type": "code",
   "source": "images['errors']",
   "id": "cc110324edbb661c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.        , 1.15695572, 1.15695572, ..., 1.73944207, 1.4453733 ,\n",
       "        1.41214692]),\n",
       " array([1.        , 1.15924423, 1.15924423, ..., 1.64210192, 1.38039943,\n",
       "        1.35471378]),\n",
       " array([1.04918256, 1.17327834, 1.17327834, ..., 1.22865496, 1.27967513,\n",
       "        1.12559913]),\n",
       " array([1.00035751, 1.12942248, 1.12942248, ..., 1.67877374, 1.68171828,\n",
       "        1.48732998]),\n",
       " array([1.        , 1.09400447, 1.09400447, ..., 1.1662555 , 1.20078226,\n",
       "        1.08364716])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
