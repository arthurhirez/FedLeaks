{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T12:44:52.864943Z",
     "start_time": "2025-05-16T12:44:51.394668Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65173a2a50c6b414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T12:44:53.545478Z",
     "start_time": "2025-05-16T12:44:53.448255Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_interval = 2\n",
    "window_size = 84\n",
    "\n",
    "batch_temporal = (agg_interval * window_size) / 24\n",
    "\n",
    "with open(f'results/exp_latente_df_graeme_{agg_interval}_{window_size}.pkl', 'rb') as file:\n",
    "    latent_dfs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad9353eb3cfd4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T12:44:54.510459Z",
     "start_time": "2025-05-16T12:44:54.416624Z"
    }
   },
   "outputs": [],
   "source": [
    "for case in latent_dfs.values():\n",
    "    for epoch in case.values():\n",
    "        date_cols = epoch['latent_space'].iloc[:, :4].reset_index(drop=True)\n",
    "        for space in epoch.keys():\n",
    "            if ('pca' in space) or ('umap' in space):\n",
    "                epoch[space] = pd.concat([date_cols, epoch[space]], axis = 1)\n",
    "                epoch[space].columns = date_cols.columns.tolist() + ['latent_1', 'latent_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f95cf63107353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T20:00:24.269401Z",
     "start_time": "2025-05-15T20:00:24.081999Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "alt.data_transformers.enable(\"vegafusion\")\n",
    "\n",
    "\n",
    "# Step 1: Combine all epoch dataframes into one DataFrame\n",
    "df_all = []\n",
    "\n",
    "for epoch, df_epoch in latent_dfs['Baseline'].items():\n",
    "    df = df_epoch['umap_raw'].copy()\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])  # Ensure timestamp format\n",
    "    df['epoch'] = epoch  # Add epoch column\n",
    "    df_all.append(df)\n",
    "\n",
    "df_combined = pd.concat(df_all, ignore_index=True)\n",
    "\n",
    "# Step 2: Create selection slider\n",
    "epoch_slider = alt.binding_range(min=df_combined['epoch'].min(),\n",
    "                                 max=df_combined['epoch'].max(),\n",
    "                                 step=1,\n",
    "                                 name='Epoch: ')\n",
    "epoch_select = alt.selection_point (fields=['epoch'], bind=epoch_slider, value = 0)\n",
    "\n",
    "# Step 3: Define heatmap chart\n",
    "heatmap = alt.Chart(df_combined).mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=100), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=100), title=\"Latent y\"),\n",
    "    color=alt.Color('label:N', scale=alt.Scale(scheme='spectral'), title='Label'),\n",
    "    tooltip=['label:N', 'epoch:Q']\n",
    ").add_params(\n",
    "    epoch_select\n",
    ").transform_filter(\n",
    "    epoch_select\n",
    ").properties(\n",
    "    width=350,\n",
    "    height=350,\n",
    "    title=\"Interactive Latent Space Heatmap by Epoch\"\n",
    ")\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d788baf-0943-4508-a194-39bdb8e81523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "client_A = pd.read_csv('datasets/leaks/Graeme/PIPELINE_PYTHON/ClientA_Baseline.csv')\n",
    "\n",
    "# Extract timestamps\n",
    "timestamps = pd.to_datetime(client_A['timestamp'], unit='s')\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Scale features (excluding timestamp)\n",
    "scaled_values = scaler.fit_transform(client_A.iloc[:, 1:])\n",
    "\n",
    "# Convert scaled data back to DataFrame with original column names (except timestamp)\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=client_A.columns[1:])\n",
    "\n",
    "# Add timestamp as the first column\n",
    "scaled_df.insert(0, 'timestamp', timestamps)\n",
    "\n",
    "# Check shape\n",
    "print(scaled_df.shape)\n",
    "scaled_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6811f-adc1-43b4-9723-a2c77f701849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Prepare data ---\n",
    "melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "\n",
    "df = df_combined[df_combined['epoch'] == 8]\n",
    "\n",
    "# Offset by feature\n",
    "unique_features = melted_df['feature'].unique()\n",
    "offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}\n",
    "melted_df['offset_value'] = melted_df.apply(\n",
    "    lambda row: row['value'] + offset_dict[row['feature']], axis=1\n",
    ")\n",
    "\n",
    "# --- Selection setup ---\n",
    "start_ts = melted_df['timestamp'].min()\n",
    "end_ts = start_ts + pd.Timedelta(days=batch_temporal)\n",
    "date_range = (start_ts.to_pydatetime(), end_ts.to_pydatetime())\n",
    "\n",
    "brush = alt.selection_interval(encodings=['x'], value={'x': date_range})\n",
    "latent_selection = alt.selection_point(fields=['timestamp'], value = melted_df['timestamp'].min())\n",
    "\n",
    "# --- Base line chart ---\n",
    "base = alt.Chart(melted_df).mark_line().encode(\n",
    "    x=alt.X('timestamp:T', title='Time'),\n",
    "    y=alt.Y('offset_value:Q', title='Offset Scaled Value'),\n",
    "    color=alt.Color('feature:N', title='Feature')\n",
    ").properties(width=500)\n",
    "\n",
    "# --- Points from latent selection (overlaid) ---\n",
    "highlighted_points = alt.Chart(melted_df).mark_circle(color='black', size=50).encode(\n",
    "    x='timestamp:T',\n",
    "    y='offset_value:Q',\n",
    "    tooltip=['feature:N', 'timestamp:T']\n",
    ").transform_filter(\n",
    "    latent_selection\n",
    ")\n",
    "\n",
    "# --- Upper (zoomed with brush, highlights added) ---\n",
    "upper = (base + highlighted_points).encode(\n",
    "    x=alt.X('timestamp:T', scale=alt.Scale(domain=brush))\n",
    ").properties(height=200)\n",
    "\n",
    "# --- Lower (overview with brush) ---\n",
    "lower = base.properties(height=60).add_params(brush)\n",
    "\n",
    "# --- Combine upper and lower ---\n",
    "time_series_chart = upper & lower\n",
    "\n",
    "# --- Latent heatmap with selection ---\n",
    "x_range = [int(df['latent_1'].min()) - 3, int(df['latent_1'].max()) + 3] \n",
    "y_range = [int(df['latent_2'].min()) - 3, int(df['latent_2'].max()) + 3]\n",
    "\n",
    "latent = alt.Chart(df).mark_rect().encode(\n",
    "    x=alt.X('latent_1:Q', bin=alt.Bin(maxbins=150), scale=alt.Scale(domain=x_range), title=\"Latent x\"),\n",
    "    y=alt.Y('latent_2:Q', bin=alt.Bin(maxbins=150), scale=alt.Scale(domain=y_range), title=\"Latent y\"),\n",
    "    color=alt.Color('label:N', scale=alt.Scale(scheme='spectral'), title='Density'),\n",
    "    tooltip=['label:N', 'timestamp:T', 'hour']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=300,\n",
    "    title=\"Latent Space (select region to highlight time)\"\n",
    ").add_params(\n",
    "    latent_selection\n",
    ").transform_filter(\n",
    "    brush\n",
    ").interactive()\n",
    "\n",
    "# --- Final layout ---\n",
    "latent | time_series_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8721d9-f15a-4ec0-84ce-2e7fd304edb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab0c46-df32-4c88-a313-734f185ecbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c089065-ea68-433f-abf6-afdf7bf4ee44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4daec-49b1-4724-af7d-99b69efc9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = scaled_df.melt(id_vars='timestamp', var_name='feature', value_name='value')\n",
    "melted_df['hour'] = melted_df['timestamp'].dt.hour\n",
    "melted_df['day'] = melted_df['timestamp'].dt.day\n",
    "\n",
    "melted_df['hour_bin'] = (melted_df['hour'] // agg_interval) * agg_interval\n",
    "\n",
    "# Assign an offset per feature\n",
    "unique_features = melted_df['feature'].unique()\n",
    "offset_dict = {feature: i * 2 for i, feature in enumerate(unique_features)}  # 2 is the vertical spacing\n",
    "\n",
    "# Apply the offset\n",
    "melted_df['offset_value'] = melted_df.apply(\n",
    "    lambda row: row['value'] + offset_dict[row['feature']], axis=1\n",
    ")\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "melted_df['timestamp'] = pd.to_datetime(melted_df['timestamp'])\n",
    "\n",
    "\n",
    "# Set up plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for feat in melted_df['feature'].unique():\n",
    "        \n",
    "    plot_df = melted_df[melted_df['feature'] == feat].copy()\n",
    "    plot_df = plot_df.iloc[:450, :]\n",
    "    # Make sure timestamp is a datetime object\n",
    "    plot_df['timestamp'] = pd.to_datetime(plot_df['timestamp'])\n",
    "    \n",
    "    # Set timestamp as index (optional but convenient for plotting)\n",
    "    plot_df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Plot full series in gray\n",
    "    plt.plot(plot_df.index, plot_df['offset_value'], color='lightgray', label='Full Series')\n",
    "    \n",
    "    # Define bins to plot and colors\n",
    "    bins_to_plot = [i for i in range (0, 12, agg_interval)]\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'purple', 'pink']\n",
    "    \n",
    "    # Loop over each bin\n",
    "    for bin_value, color in zip(bins_to_plot, colors):\n",
    "        for day in plot_df['day'].unique():\n",
    "            # Define the 4-hour window starting at bin_value\n",
    "            hour_range = [(bin_value + i) % 24 for i in range(4)]\n",
    "            \n",
    "            # Select the rows within that 4-hour window for the current day\n",
    "            mask = (plot_df['day'] == day) & (plot_df['hour'].isin(hour_range))\n",
    "            segment = plot_df[mask]\n",
    "    \n",
    "            # Plot the segment\n",
    "            plt.plot(segment.index, segment['offset_value'], color=color, label=f'Bin {bin_value}' if day == plot_df['day'].unique()[0] else \"\")\n",
    "    \n",
    "            # Define the 4-hour window starting at bin_value\n",
    "            hour_range = [(bin_value +12 + i) for i in range(4)]\n",
    "            \n",
    "            # Select the rows within that 4-hour window for the current day\n",
    "            mask = (plot_df['day'] == day) & (plot_df['hour'].isin(hour_range))\n",
    "            segment = plot_df[mask]\n",
    "    \n",
    "            # Plot the segment\n",
    "            plt.plot(segment.index, segment['offset_value'], color=color, label=f'Bin {bin_value}' if day == plot_df['day'].unique()[0] else \"\")\n",
    "        \n",
    "# Formatting\n",
    "plt.title(f'Series Highlighted for Hour Bins: {bins_to_plot} (4-hour blocks)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Offset Value')\n",
    "# plt.legend(loc='upper left', fontsize=8)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d1a5c-790f-47f8-a36c-79498eaa619e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea71503-7d7c-45c4-86e1-8796657781e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f8fc5-16f7-4270-ae21-621ae8acda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Raw and transformed data\n",
    "transformed = results['Baseline']['dl'][0]['X'][0]       # shape: (200, 5)\n",
    "\n",
    "# Determine aggregation window\n",
    "agg_window = 3\n",
    "lenght_raw = transformed.shape[0] * agg_window\n",
    "raw_scaled = scaler.fit_transform(client_A.iloc[:lenght_raw, 1:], (-1, 1))  # shape: (600, 5)\n",
    "\n",
    "# Time axes\n",
    "time_raw = np.arange(raw_scaled.shape[0])\n",
    "time_transformed = np.arange(transformed.shape[0]) * agg_window + agg_window // 2  # center of each window\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "offset = 2  # vertical offset to separate each feature\n",
    "\n",
    "for i in range(raw_scaled.shape[1]):\n",
    "    # Offset for clarity\n",
    "    plt.plot(time_raw, raw_scaled[:, i] + i * offset, color='lightgray', label=f'Raw Feature {i+1}' if i == 0 else \"\")\n",
    "    plt.plot(time_transformed, transformed[:, i] + i * offset, label=f'Transformed Feature {i+1}')\n",
    "\n",
    "plt.title('Raw vs Transformed (Aggregated) Multivariate Time Series')\n",
    "plt.xlabel('Time Step')\n",
    "plt.yticks([i * offset for i in range(raw_scaled.shape[1])],\n",
    "           [f'Feature {i+1}' for i in range(raw_scaled.shape[1])])\n",
    "plt.legend(bbox_to_anchor = (1,1))\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TsLeaks]",
   "language": "python",
   "name": "conda-env-TsLeaks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
